{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U torch torchaudio torchdata torchtext torchvision torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: 1.9.0 not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken\n",
    "!pip install modelscope\n",
    "!pip install transformers_stream_generator==0.0.4\n",
    "!pip install optimum==1.12.0\n",
    "!pip install auto-gptq\n",
    "# %pip install transformers_stream_generator==0.0.4\n",
    "# %pip install modelscope   #>=1.9.0\n",
    "# %pip install auto-gptq  #==0.4.2\n",
    "# %pip install optimum==1.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone -b v1.0.8 https://github.com/Dao-AILab/flash-attention\n",
    "!cd flash-attention && pip install .\n",
    "# 下方安装可选，安装可能比较缓慢。\n",
    "# Below are optional. Installing them might be slow.\n",
    "# pip install csrc/layer_norm\n",
    "# pip install csrc/rotary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 18:05:39,577 - modelscope - INFO - PyTorch version 2.1.0 Found.\n",
      "2023-11-24 18:05:39,578 - modelscope - INFO - Loading ast index from /Users/jxy/.cache/modelscope/ast_indexer\n",
      "2023-11-24 18:05:39,677 - modelscope - INFO - No valid ast index found from /Users/jxy/.cache/modelscope/ast_indexer, generating ast index from prebuilt!\n",
      "2023-11-24 18:05:39,711 - modelscope - INFO - Loading done! Current index file version is 1.9.5, with md5 a814d16a7ee2539750fe2738e7c8eb07 and a total number of 945 components indexed\n",
      "/Users/jxy/miniconda3/envs/stock/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading: 100%|██████████| 8.21k/8.21k [00:00<00:00, 2.20MB/s]\n",
      "Downloading: 100%|██████████| 50.8k/50.8k [00:00<00:00, 159kB/s]\n",
      "Downloading: 100%|██████████| 1.44k/1.44k [00:00<00:00, 778kB/s]\n",
      "Downloading: 100%|██████████| 48.0/48.0 [00:00<00:00, 15.7kB/s]\n",
      "Downloading: 100%|██████████| 2.29k/2.29k [00:00<00:00, 790kB/s]\n",
      "Downloading: 100%|██████████| 1.88k/1.88k [00:00<00:00, 660kB/s]\n",
      "Downloading: 100%|██████████| 250/250 [00:00<00:00, 94.7kB/s]\n",
      "Downloading: 100%|██████████| 6.73k/6.73k [00:00<00:00, 661kB/s]\n",
      "Downloading: 100%|██████████| 56.3k/56.3k [00:00<00:00, 167kB/s]\n",
      "Downloading: 100%|█████████▉| 9.05G/9.05G [05:45<00:00, 28.1MB/s]\n",
      "Downloading: 100%|██████████| 223/223 [00:00<00:00, 50.2kB/s]\n",
      "Downloading: 100%|██████████| 2.49M/2.49M [00:01<00:00, 2.11MB/s]\n",
      "Downloading: 100%|██████████| 14.3k/14.3k [00:00<00:00, 4.15MB/s]\n",
      "Downloading: 100%|██████████| 4.81k/4.81k [00:00<00:00, 1.57MB/s]\n",
      "Downloading: 100%|██████████| 9.51k/9.51k [00:00<00:00, 3.41MB/s]\n",
      "Downloading: 100%|██████████| 174/174 [00:00<00:00, 118kB/s]\n"
     ]
    }
   ],
   "source": [
    "from modelscope import AutoModelForCausalLM, AutoTokenizer, snapshot_download\n",
    "from modelscope import GenerationConfig\n",
    "\n",
    "model_dir = snapshot_download('TongyiFinance/Tongyi-Finance-14B-Chat-Int4')\n",
    "\n",
    "# Note: The default behavior now has injection attack prevention off.\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected the presence of a `quantization_config` attribute in the model's configuration but you don't have the correct `bitsandbytes` version to support int8 serialization. Please install the latest version of `bitsandbytes` with  `pip install --upgrade bitsandbytes`.\n"
     ]
    }
   ],
   "source": [
    "from modelscope import AutoModelForCausalLM, AutoTokenizer, snapshot_download\n",
    "from modelscope import GenerationConfig\n",
    "\n",
    "model_dir = snapshot_download('TongyiFinance/Tongyi-Finance-14B-Chat-Int4')\n",
    "\n",
    "# Note: The default behavior now has injection attack prevention off.\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True)\n",
    "\n",
    "# use bf16\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_dir, device_map=\"auto\", trust_remote_code=True, bf16=True).eval()\n",
    "# use cpu only\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_dir, device_map=\"cpu\", trust_remote_code=True).eval()\n",
    "# use auto mode, automatically select precision based on the device.\n",
    "model = AutoModelForCausalLM.from_pretrained(model_dir, device_map=\"cpu\", trust_remote_code=True).eval()\n",
    "# 模型加载指定device_map='cuda:0'，更改成device_map='auto'会使用所有可用显卡\n",
    "\n",
    "# Specify hyperparameters for generation\n",
    "model.generation_config = GenerationConfig.from_pretrained(model_dir, trust_remote_code=True)\n",
    "\n",
    "response, history = model.chat(tokenizer, \"请解释一下资产负债率\", history=None)\n",
    "print(response)\n",
    "# 资产负债率是一个财务比率，用来衡量一个企业的负债水平。它是用一个企业负债总额除以其资产总额的百分比来表示的。它的计算公式是：资产负债率 = 负债总额 / 资产总额。它能够反映一个企业的财务状况，以及它是否具有足够的资产来抵偿其债务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelscope import AutoModelForCausalLM, AutoTokenizer, snapshot_download\n",
    "from modelscope import GenerationConfig\n",
    "\n",
    "model_dir = snapshot_download('TongyiFinance/Tongyi-Finance-14B')\n",
    "\n",
    "# Note: The default behavior now has injection attack prevention off.\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True)\n",
    "\n",
    "# use bf16\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_dir, device_map=\"cuda:0\", trust_remote_code=True, bf16=True).eval()\n",
    "# use cpu only\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_dir, device_map=\"cpu\", trust_remote_code=True).eval()\n",
    "model = AutoModelForCausalLM.from_pretrained(model_dir, device_map=\"cuda:0\", trust_remote_code=True).eval()\n",
    "# 模型加载指定device_map='cuda:0'，更改成device_map='auto'会使用所有可用显卡\n",
    "\n",
    "# Specify hyperparameters for generation\n",
    "model.generation_config = GenerationConfig.from_pretrained(model_dir, trust_remote_code=True)\n",
    "\n",
    "inputs = tokenizer('市盈率是最常用来评估股价水平是否合理的指标之一，是指', return_tensors='pt')\n",
    "inputs = inputs.to(model.device)\n",
    "pred = model.generate(**inputs)\n",
    "print(tokenizer.decode(pred.cpu()[0], skip_special_tokens=True))\n",
    "# 市盈率是最常用来评估股价水平是否合理的指标之一，是指股票价格与每股盈利的比率。..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
